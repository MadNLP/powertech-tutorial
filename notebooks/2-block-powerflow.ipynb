{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial 2: solving the power-flow equations in batch on the GPU\n",
    "\n",
    "In the previous tutorial, we have seen how to solve the power flow equations\n",
    "using ExaModels. We now want to fully leverage the capability of ExaModels,\n",
    "and solve the power flow equations in batch on the GPU.\n",
    "\n",
    "We start by importing the usual packages:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "get_block_reordering (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "cell_type": "code",
   "source": [
    "using LinearAlgebra\n",
    "using SparseArrays\n",
    "\n",
    "using NLPModels\n",
    "using ExaModels\n",
    "\n",
    "using JLD2\n",
    "\n",
    "include(\"utils.jl\")"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "We load again the instance case9ieee:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "9"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "cell_type": "code",
   "source": [
    "DATA_DIR = \"/home/fpacaud/dev/examodels-tutorials/instances\"\n",
    "data = JLD2.load(joinpath(DATA_DIR, \"case9.jld2\"))[\"data\"]\n",
    "\n",
    "nbus = length(data.bus)\n",
    "ngen = length(data.gen)\n",
    "nlines = length(data.branch)"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Block power flow with ExaModels\n",
    "\n",
    "The power flow are parameterized by the active and reactive power loads\n",
    "$p_d$ and $q_d$ we have at each bus, among others. This gives a total\n",
    "of `2*nbus` parameters.\n",
    "\n",
    "In this tutorial, we want to solve the power flow equations in batch for\n",
    "different loads $\\{ p_d^n, q_d^n \\}_{n=1,⋯,N}$, with $N$ playing the role of the batch size.\n",
    "To each realization $(p_d^n, q_d^n)$ is associated a block. The number of blocks is the batch size $N$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a demonstration, we set the batch size to 100:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "100"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "N = 100"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "For each parameters $(p_d^n, q_d^n)$ is associated a given solution\n",
    "$(v_m^n, v_a^n, p_g^n, q_g^n)$ of the power flow equations. We will look at computing\n",
    "all the solutions in parallel using Newton."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using ExaModels, we can define the corresponding block model by augmenting the\n",
    "dimension of each variable with a second dimension parameterized by $N$, the batch size.\n",
    "This amounts to define the following variables:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Variable\n\n  x ∈ R^{18 × 100}\n"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "core = ExaModels.ExaCore()\n",
    "va = ExaModels.variable(core, nbus, 1:N)\n",
    "vm = ExaModels.variable(core, nbus, 1:N; start = repeat(data.vm0, N))\n",
    "pg = ExaModels.variable(core, ngen, 1:N;  start=repeat(data.pg0, N))\n",
    "qg = ExaModels.variable(core, ngen, 1:N;  start=repeat(data.qg0, N))\n",
    "p = ExaModels.variable(core, 2*nlines, 1:N)\n",
    "q = ExaModels.variable(core, 2*nlines, 1:N)"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that we have to duplicate $N$ times the starting point for $v_m$, $p_g$ and $q_g$.\n",
    "We have also to evaluate the power flow constraint in block. As a consequence, the iterator\n",
    "used to generate each constraint has to be modified using the iterator `product`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Constraint\n\n  s.t. (...)\n       g♭ ≤ [g(x,p)]_{p ∈ P} ≤ g♯\n\n  where |P| = 900\n"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "cell_type": "code",
   "source": [
    "c2 = ExaModels.constraint(\n",
    "    core,\n",
    "    p[b.f_idx, k]\n",
    "    - b.c5 * vm[b.f_bus, k]^2 -\n",
    "    b.c3 * (vm[b.f_bus, k] * vm[b.t_bus, k] * cos(va[b.f_bus, k] - va[b.t_bus, k])) -\n",
    "    b.c4 * (vm[b.f_bus, k] * vm[b.t_bus, k] * sin(va[b.f_bus, k] - va[b.t_bus, k])) for\n",
    "    (b, k) in product(data.branch, 1:N)\n",
    ")"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "To avoid redefining all the models, we provide a utility function to generate the\n",
    "block power flow model using ExaModels:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "An ExaModel{Float64, Vector{Float64}, ...}\n\n  Problem name: Generic\n   All variables: ████████████████████ 6000   All constraints: ████████████████████ 6000  \n            free: ████████████████████ 6000              free: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n           lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n           upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n         low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0              low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n           fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                fixed: ████████████████████ 6000  \n          infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n            nnzh: ( 99.79% sparsity)   37800           linear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n                                                    nonlinear: ████████████████████ 6000  \n                                                         nnzj: ( 99.93% sparsity)   24600 \n\n"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "include(\"powerflow.jl\")\n",
    "\n",
    "nlp = block_power_flow_model(data, N)"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "The power flow model can be solved on the CPU using the function\n",
    "`solve_power_flow` we implemented in the previous tutorial:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: It: 1 residual: 28.281211961300386\n",
      "[ Info: It: 2 residual: 1.6641541672388813\n",
      "[ Info: It: 3 residual: 0.03123124093240232\n",
      "[ Info: It: 4 residual: 7.791517832863897e-6\n",
      "[ Info: It: 5 residual: 6.342121166249363e-13\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "results = solve_power_flow(nlp, N)\n",
    "nothing"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "We recover the solution in matrix format using:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "9×100 Matrix{Float64}:\n 0.975472  0.975472  0.975472  0.975472  …  0.975472  0.975472  0.975472\n 0.987007  0.987007  0.987007  0.987007     0.987007  0.987007  0.987007\n 1.00338   1.00338   1.00338   1.00338      1.00338   1.00338   1.00338\n 0.985645  0.985645  0.985645  0.985645     0.985645  0.985645  0.985645\n 1.0       1.0       1.0       1.0          1.0       1.0       1.0\n 0.957621  0.957621  0.957621  0.957621  …  0.957621  0.957621  0.957621\n 0.996185  0.996185  0.996185  0.996185     0.996185  0.996185  0.996185\n 1.0       1.0       1.0       1.0          1.0       1.0       1.0\n 1.0       1.0       1.0       1.0          1.0       1.0       1.0"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "cell_type": "code",
   "source": [
    "vm = reshape(results[nbus*N+1:2*nbus*N], nbus, N)"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Solving the power flow equations in batch on the GPU\n",
    "\n",
    "Note that here we don't exploit in the solution method the fact that the $N$ blocks are independent.\n",
    "ExaModels is able to detect the repeated data structure automatically, and can evaluate them in\n",
    "parallel on the GPU. That's the core benefit of the SIMD abstraction used by ExaModels.\n",
    "To evaluate the model on the GPU using ExaModels, you just have to pass the correct backend\n",
    "to the function `block_power_flow_model` we used just before:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "24600"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "cell_type": "code",
   "source": [
    "using CUDA\n",
    "nlp_gpu = block_power_flow_model(data, N; backend=CUDABackend())\n",
    "\n",
    "n = NLPModels.get_nvar(nlp_gpu)\n",
    "m = NLPModels.get_ncon(nlp_gpu)\n",
    "nnzj = NLPModels.get_nnzj(nlp_gpu)"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluating the model on the GPU simply amounts to"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6000-element CUDA.CuArray{Float64, 1, CUDA.DeviceMemory}:\n  0.0\n  0.0\n  0.0\n  0.0\n  0.0\n  0.0\n  0.0\n  0.0\n  0.0\n  0.0\n  ⋮\n  0.3\n  0.0\n  0.0\n  0.35\n -0.0654\n  0.5\n  0.0\n  0.10949999999999999\n -0.2703"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "cell_type": "code",
   "source": [
    "x0 = NLPModels.get_x0(nlp_gpu)\n",
    "c = similar(x0, m)\n",
    "NLPModels.cons!(nlp_gpu, x0, c)"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "for the power flow residual, and for the Jacobian:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "24600-element CUDA.CuArray{Float64, 1, CUDA.DeviceMemory}:\n  1.0\n  1.0\n  1.0\n  1.0\n  1.0\n  1.0\n  1.0\n  1.0\n  1.0\n  1.0\n  ⋮\n -1.0\n -1.0\n -1.0\n -1.0\n -1.0\n -1.0\n -1.0\n -1.0\n -1.0"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "cell_type": "code",
   "source": [
    "Jx = similar(x0, nnzj)\n",
    "NLPModels.jac_coord!(nlp_gpu, x0, Jx)"
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can benchmark the time spent in the evaluation of the derivative\n",
    "using the macro `@time`, or `CUDA.@time` if we want also to include the\n",
    "synchronization time in CUDA:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000294 seconds (933 CPU allocations: 42.953 KiB)\n",
      "  0.000339 seconds (930 CPU allocations: 42.938 KiB)\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "CUDA.@time NLPModels.cons!(nlp_gpu, x0, c)\n",
    "CUDA.@time NLPModels.jac_coord!(nlp_gpu, x0, Jx)\n",
    "nothing"
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "We observe that the evaluation of the Jacobian takes 0.3ms in this case.\n",
    "In the function `analyse_sparsity`, we provide a sparse routine to extract the submatrix corresponding to the power flow equations\n",
    "from the Jacobian J. Note that on the GPU, the default format for sparse matrices is CSR, as this\n",
    "leads to better parallelism when computing sparse-matrix vector products."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can assemble the submatrix `G` using this new function:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(sparse(Int32[5, 8, 905, 908, 1805, 1808, 2705, 2708, 5, 6  …  3596, 5392, 3597, 5393, 3598, 5397, 3599, 5394, 3600, 5393], Int32[1, 1, 1, 1, 1, 1, 1, 1, 2, 2  …  5396, 5396, 5397, 5397, 5398, 5398, 5399, 5399, 5400, 5400], [625.0, 639.0, 5125.0, 5139.0, 9624.0, 9640.0, 14124.0, 14140.0, 624.0, 630.0  …  18576.0, 23996.0, 18581.0, 23997.0, 18586.0, 23998.0, 18591.0, 23999.0, 18596.0, 24000.0], 5400, 5400), [604, 605, 602, 603, 601, 610, 609, 608, 606, 614  …  23988, 23998, 20398, 23986, 23989, 23994, 24599, 23984, 24600, 23991])"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "cell_type": "code",
   "source": [
    "ind_dof = get_index_dof(data, N)\n",
    "m_fixed = length(ind_dof)\n",
    "ind_dep = setdiff(1:n, ind_dof)\n",
    "nx = length(ind_dep)\n",
    "\n",
    "Ji = similar(x0, Int, nnzj)\n",
    "Jj = similar(x0, Int, nnzj)\n",
    "NLPModels.jac_structure!(nlp_gpu, Ji, Jj)\n",
    "\n",
    "G, coo_to_csr = analyse_sparsity(Ji, Jj, Jx, m, n, m_fixed, ind_dep)"
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now the Jacobian is evaluated, we have to compute the LU factorization on the GPU,\n",
    "if possible in sparse format. The solver [cuDSS](https://docs.nvidia.com/cuda/cudss/getting_started.html) allows to do exactly that. To use cuDSS in Julia, you have to import CUDSS"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using CUDSS"
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "We update the values in the Jacobian of the original model and transfer them to `G`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "21600-element CUDA.CuArray{Float64, 1, CUDA.DeviceMemory}:\n  -9.784270426363172\n   9.784270426363172\n  -1.1550874808900968\n   1.1550874808900968\n   1.0\n  17.064846416382252\n -17.064846416382252\n   0.0\n   1.0\n -13.697978596908442\n   ⋮\n   1.0\n   0.0\n   1.0\n   1.0\n   1.0\n  -1.0\n   1.0\n  -1.0\n   1.0"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "cell_type": "code",
   "source": [
    "NLPModels.jac_coord!(nlp_gpu, x0, Jx)\n",
    "nonzeros(G) .= Jx[coo_to_csr]"
   ],
   "metadata": {},
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "The symbolic factorization in cuDSS proceeds as follows:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "d_gpu = CUDA.zeros(Float64, nx)\n",
    "b_gpu = CUDA.zeros(Float64, nx)\n",
    "\n",
    "solver = CudssSolver(G, \"G\", 'F')\n",
    "cudss_set(solver, \"reordering_alg\", \"algo2\") # we have to change the ordering to get valid results\n",
    "cudss(\"analysis\", solver, d_gpu, b_gpu)"
   ],
   "metadata": {},
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hence, we are now able to replace KLU by CUDSS in the Newton solver we implemented\n",
    "in the previous tutorial.\n",
    "We initialize the Newton algorithm by evaluating the model at the initial point:"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Info: Solving the power flow equations with Newton\n",
      "[ Info: It: 1 residual: 28.281211961300375\n",
      "[ Info: It: 2 residual: 1.6641541672388802\n",
      "[ Info: It: 3 residual: 0.0312312409324013\n",
      "[ Info: It: 4 residual: 7.791517848073391e-6\n",
      "[ Info: It: 5 residual: 6.267407062724004e-13\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "ind_dep = CuVector{Int}(ind_dep)\n",
    "x = copy(x0)\n",
    "c = similar(x0, m)\n",
    "residual = view(c, m_fixed+1:m)      # get subvector associated to the power flow residual\n",
    "\n",
    "NLPModels.cons!(nlp_gpu, x, c)\n",
    "\n",
    "cudss(\"factorization\", solver, d_gpu, b_gpu)\n",
    "\n",
    "max_iter = 10\n",
    "tol = 1e-8\n",
    "\n",
    "@info \"Solving the power flow equations with Newton\"\n",
    "i = 1\n",
    "for i in 1:max_iter\n",
    "    @info \"It: $(i) residual: $(norm(residual))\"\n",
    "    if norm(residual) <= tol\n",
    "        break\n",
    "    end\n",
    "    NLPModels.jac_coord!(nlp_gpu, x, Jx) # Update values in Jacobian\n",
    "    nonzeros(G) .= Jx[coo_to_csr]\n",
    "    cudss_set(solver, G)                 # Update numerical factorization\n",
    "    cudss(\"refactorization\", solver, d_gpu, b_gpu)\n",
    "    b_gpu .= residual\n",
    "    cudss(\"solve\", solver, d_gpu, b_gpu)\n",
    "    x[ind_dep] .-= d_gpu\n",
    "    NLPModels.cons!(nlp_gpu, x, c)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "We observe that we get exactly the same convergence as before on the CPU.\n",
    "However, the time to solution is significantly higher than on the CPU: it turns out that\n",
    "KLU is much more efficient than cuDSS on this particular example."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.5",
   "language": "julia"
  }
 },
 "nbformat": 4
}
