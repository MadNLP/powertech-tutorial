{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial 2: solving the power-flow equations in batch on the GPU\n",
    "\n",
    "In the previous tutorial, we have seen how to solve the power flow equations\n",
    "using ExaModels. We now want to fully leverage the capability of ExaModels,\n",
    "and solve the power flow equations in batch on the GPU.\n",
    "\n",
    "We start by importing the usual packages:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using LinearAlgebra\n",
    "using SparseArrays\n",
    "\n",
    "using NLPModels\n",
    "using ExaModels\n",
    "\n",
    "using JLD2\n",
    "\n",
    "include(\"utils.jl\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We load again the instance case9ieee:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "data = JLD2.load(\"instances/case9.jld2\")[\"data\"]\n",
    "\n",
    "nbus = length(data.bus)\n",
    "ngen = length(data.gen)\n",
    "nlines = length(data.branch)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The power flow are parameterized by the active and reactive power loads\n",
    "$p_d$ and $q_d$ we have at each bus, among others. This gives a total\n",
    "of `2*nbus` parameters.\n",
    "\n",
    "In this tutorial, we want to solve the power flow equations in batch for\n",
    "different loads $\\{ p_d^n, q_d^n \\}_{n=1,â‹¯,N}$, with $N$ playing the role of the batch size.\n",
    "To each realization $(p_d^n, q_d^n)$ is associated a block. The number of blocks is the batch size $N$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a demonstration, we set the batch size to 100:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "N = 100"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For each parameters $(p_d^n, q_d^n)$ is associated a given solution\n",
    "$(v_m^n, v_a^n, p_g^n, q_g^n)$ of the power flow equations. We will look at computing\n",
    "all the solutions in parallel using Newton."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using ExaModels, we can define the corresponding block model by augmenting the\n",
    "dimension of each variable with a second dimension parameterized by $N$, the batch size.\n",
    "This amounts to define the following variables:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "core = ExaModels.ExaCore()\n",
    "va = ExaModels.variable(core, nbus, 1:N)\n",
    "vm = ExaModels.variable(core, nbus, 1:N; start = repeat(data.vm0, N))\n",
    "pg = ExaModels.variable(core, ngen, 1:N;  start=repeat(data.pg0, N))\n",
    "qg = ExaModels.variable(core, ngen, 1:N;  start=repeat(data.qg0, N))\n",
    "p = ExaModels.variable(core, 2*nlines, 1:N)\n",
    "q = ExaModels.variable(core, 2*nlines, 1:N)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that we have to duplicate $N$ times the starting point for $v_m$, $p_g$ and $q_g$.\n",
    "We have also to evaluate the power flow constraint in block. As a consequence, the iterator\n",
    "used to generate each constraint has to be modified using the iterator `product`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "c2 = ExaModels.constraint(\n",
    "    core,\n",
    "    p[b.f_idx, k]\n",
    "    - b.c5 * vm[b.f_bus, k]^2 -\n",
    "    b.c3 * (vm[b.f_bus, k] * vm[b.t_bus, k] * cos(va[b.f_bus, k] - va[b.t_bus, k])) -\n",
    "    b.c4 * (vm[b.f_bus, k] * vm[b.t_bus, k] * sin(va[b.f_bus, k] - va[b.t_bus, k])) for\n",
    "    (b, k) in product(data.branch, 1:N)\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "To avoid redefining all the models, we provide a utility function to generate the\n",
    "block power flow model using ExaModels:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "include(\"powerflow.jl\")\n",
    "\n",
    "nlp = block_power_flow_model(data, N)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The power flow model can be solved on the CPU using the function\n",
    "`solve_power_flow` we implemented in the previous tutorial:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "results = solve_power_flow(nlp, N)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We recover the solution in matrix format using:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "vm = reshape(results[nbus*N+1:2*nbus*N], nbus, N)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that here we don't exploit in the solution method the fact that the $N$ blocks are independent.\n",
    "ExaModels is able to detect the repeated data structure automatically, and can evaluate them in\n",
    "parallel on the GPU. That's the core benefit of the SIMD abstraction used by ExaModels.\n",
    "To evaluate the model on the GPU using ExaModels, you just have to pass the correct backend\n",
    "to the function `block_power_flow_model` we used just before:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using CUDA\n",
    "nlp_gpu = block_power_flow_model(data, N; backend=CUDABackend())\n",
    "\n",
    "n = NLPModels.get_nvar(nlp_gpu)\n",
    "m = NLPModels.get_ncon(nlp_gpu)\n",
    "nnzj = NLPModels.get_nnzj(nlp_gpu)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluating the model on the GPU simply amounts to"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "x0 = NLPModels.get_x0(nlp_gpu)\n",
    "c = similar(x0, m)\n",
    "NLPModels.cons!(nlp_gpu, x0, c)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "for the power flow residual, and for the Jacobian:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Jx = similar(x0, nnzj)\n",
    "NLPModels.jac_coord!(nlp_gpu, x0, Jx)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can benchmark the time spent in the evaluation of the derivative\n",
    "using the macro `@time`, or `CUDA.@time` if we want also to include the\n",
    "synchronization time in CUDA:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "CUDA.@time NLPModels.cons!(nlp_gpu, x0, c)\n",
    "CUDA.@time NLPModels.jac_coord!(nlp_gpu, x0, Jx)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We observe that the evaluation of the Jacobian takes 0.3ms in this case.\n",
    "In the function `analyse_sparsity`, we provide a sparse routine to extract the submatrix corresponding to the power flow equations\n",
    "from the Jacobian J. Note that on the GPU, the default format for sparse matrices is CSR, as this\n",
    "leads to better parallelism when computing sparse-matrix vector products."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can assemble the submatrix `G` using this new function:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ind_dof = get_index_dof(data, N)\n",
    "m_fixed = length(ind_dof)\n",
    "ind_dep = setdiff(1:n, ind_dof)\n",
    "nx = length(ind_dep)\n",
    "\n",
    "Ji = similar(x0, Int, nnzj)\n",
    "Jj = similar(x0, Int, nnzj)\n",
    "NLPModels.jac_structure!(nlp_gpu, Ji, Jj)\n",
    "\n",
    "G, coo_to_csr = analyse_sparsity(Ji, Jj, Jx, m, n, m_fixed, ind_dep)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now the Jacobian is evaluated, we have to compute the LU factorization on the GPU,\n",
    "if possible in sparse format. The solver [cuDSS](https://docs.nvidia.com/cuda/cudss/getting_started.html) allows to do exactly that. To use cuDSS in Julia, you have to import CUDSS"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using CUDSS"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We update the values in the Jacobian of the original model and transfer them to `G`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "NLPModels.jac_coord!(nlp_gpu, x0, Jx)\n",
    "nonzeros(G) .= Jx[coo_to_csr]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The symbolic factorization in cuDSS proceeds as follows:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "d_gpu = CUDA.zeros(Float64, nx)\n",
    "b_gpu = CUDA.zeros(Float64, nx)\n",
    "\n",
    "solver = CudssSolver(G, \"G\", 'F')\n",
    "cudss_set(solver, \"reordering_alg\", \"algo2\") # we have to change the ordering to get valid results\n",
    "cudss(\"analysis\", solver, d_gpu, b_gpu)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hence, we are now able to replace KLU by CUDSS in the Newton solver we implemented\n",
    "in the previous tutorial.\n",
    "We initialize the Newton algorithm by evaluating the model at the initial point:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ind_dep = CuVector{Int}(ind_dep)\n",
    "x = copy(x0)\n",
    "c = similar(x0, m)\n",
    "residual = view(c, m_fixed+1:m)      # get subvector associated to the power flow residual\n",
    "\n",
    "NLPModels.cons!(nlp_gpu, x, c)\n",
    "\n",
    "cudss(\"factorization\", solver, d_gpu, b_gpu)\n",
    "\n",
    "max_iter = 10\n",
    "tol = 1e-8\n",
    "\n",
    "@info \"Solving the power flow equations with Newton\"\n",
    "i = 1\n",
    "for i in 1:max_iter\n",
    "    @info \"It: $(i) residual: $(norm(residual))\""
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Stopping criterion"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "    if norm(residual) <= tol\n",
    "        break\n",
    "    end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Update values in Jacobian"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "    NLPModels.jac_coord!(nlp_gpu, x, Jx)\n",
    "    nonzeros(G) .= Jx[coo_to_csr]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Update numerical factorization"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "    cudss_set(solver, G)\n",
    "    cudss(\"refactorization\", solver, d_gpu, b_gpu)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compute Newton direction using a backsolve"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "    b_gpu .= residual\n",
    "    cudss(\"solve\", solver, d_gpu, b_gpu)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Update dependent variables"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "    x[ind_dep] .-= d_gpu"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Refresh residuals"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "    NLPModels.cons!(nlp_gpu, x, c)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We observe that we get exactly the same convergence as before on the CPU."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.5",
   "language": "julia"
  }
 },
 "nbformat": 4
}
